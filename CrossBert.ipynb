{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CrossBert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrxwJYHkoisA",
        "outputId": "708586c9-95a0-4669-bdfd-7374718a8232"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 27 14:39:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "7oE7aF6vnsZR",
        "outputId": "8de394a1-456c-48d2-ea16-2b06964694dd"
      },
      "source": [
        "#Creates arra\n",
        "import csv\n",
        "products = []\n",
        "with open('/content/products.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    for row in csv_reader:\n",
        "        products.append(row)\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            #print(f'\\t product_id :{row[0]}| product_name: {row[1]} | aisle_id: {row[2]} | department_id : {row[3]}')\n",
        "            line_count += 1\n",
        "    print(f'Processed {line_count} lines.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-46817323af82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/products.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcsv_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mline_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/products.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eLZUOJ5nwbB"
      },
      "source": [
        "#Function gives aisle id of a product\n",
        "def getAisleID(product_id):\n",
        "    target = int(product_id)\n",
        "    skipfirstline = 0\n",
        "    for i in products:\n",
        "        if skipfirstline == 0:\n",
        "            skipfirstline = 1\n",
        "            continue\n",
        "        product = int(i[0])\n",
        "        if (product==target):\n",
        "            aisle_id = int(i[2])\n",
        "            return aisle_id\n",
        "    print(\"product not found\")\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNc1f8vvnyYU"
      },
      "source": [
        "#Remove categories not in analysis\n",
        "def removeCategories(order):\n",
        "    acceptedCategories = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "    for i in order:\n",
        "        if i[1] not in acceptedCategories:\n",
        "            order.remove(i)\n",
        "    return order\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "V7CYevxfn1J1",
        "outputId": "bab1db7c-1909-42cd-8a6a-7c21f989e259"
      },
      "source": [
        "#Creates training data\n",
        "import csv\n",
        "train_orders=[]\n",
        "with open('/content/order_products__prior.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    order_count=0\n",
        "    prev=-1\n",
        "    i=0\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            #print(f'\\t product_id :{row[0]}| product_name: {row[1]} | aisle_id: {row[2]} | department_id : {row[3]}')\n",
        "                if (int(row[0])!=prev):\n",
        "                    order_count+=1\n",
        "                    i=1\n",
        "                order_basket = [int(row[0]),getAisleID(int(row[1]))]\n",
        "                train_orders.append(order_basket)\n",
        "                #train_orders = removeCategories(train_orders)\n",
        "                prev = int(row[0])\n",
        "                line_count += 1\n",
        "                if (order_count%500==0 and i==1):\n",
        "                    print(order_count, \"of\", \"30000\")\n",
        "                    i=0\n",
        "                if(order_count>30000):\n",
        "                #if(order_count>5000):\n",
        "                    break\n",
        "    print(f'Processed {line_count} lines.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names are order_id, product_id, add_to_cart_order, reordered\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1cafd5ea9626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0morder_count\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0morder_basket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgetAisleID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mtrain_orders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_basket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#train_orders = removeCategories(train_orders)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c2fe2a73264d>\u001b[0m in \u001b[0;36mgetAisleID\u001b[0;34m(product_id)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mskipfirstline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0maisle_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJJbGeGg_0SJ",
        "outputId": "33ec126e-3009-4aa1-fc9d-6d31d5cae585"
      },
      "source": [
        "#creates evaluation data\n",
        "import csv\n",
        "eval_orders=[]\n",
        "with open('/content/order_products__train.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    order_count=0\n",
        "    prev=-1\n",
        "    i=0\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            #print(f'\\t product_id :{row[0]}| product_name: {row[1]} | aisle_id: {row[2]} | department_id : {row[3]}')\n",
        "                if (int(row[0])!=prev):\n",
        "                    order_count+=1\n",
        "                    i=1\n",
        "                order_basket_eval = [int(row[0]),getAisleID(int(row[1]))]\n",
        "                eval_orders.append(order_basket_eval)\n",
        "                #train_orders = removeCategories(train_orders)\n",
        "                prev = int(row[0])\n",
        "                line_count += 1\n",
        "                if (order_count%500==0 and i==1):\n",
        "                    print(order_count, \"of\", \"10000\")\n",
        "                    i=0\n",
        "                if(order_count>10000):\n",
        "                    break\n",
        "    print(f'Processed {line_count} lines.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names are order_id, product_id, add_to_cart_order, reordered\n",
            "500 of 10000\n",
            "1000 of 10000\n",
            "1500 of 10000\n",
            "2000 of 10000\n",
            "2500 of 10000\n",
            "3000 of 10000\n",
            "3500 of 10000\n",
            "4000 of 10000\n",
            "4500 of 10000\n",
            "5000 of 10000\n",
            "5500 of 10000\n",
            "6000 of 10000\n",
            "6500 of 10000\n",
            "7000 of 10000\n",
            "7500 of 10000\n",
            "8000 of 10000\n",
            "8500 of 10000\n",
            "9000 of 10000\n",
            "9500 of 10000\n",
            "10000 of 10000\n",
            "Processed 105406 lines.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "lD9IX3XRpCvV",
        "outputId": "3dead6f6-8f38-4040-a76c-eb431398117f"
      },
      "source": [
        "#Data processing\n",
        "orders=[]\n",
        "order_binary=[[0 for x in range(135)] for y in range(1)]\n",
        "orders_binary = []\n",
        "for i in train_orders: \n",
        "    if(int(i[0])!=prev):\n",
        "        baskets=[]\n",
        "        orders.append(baskets)\n",
        "    baskets.append(i[1])\n",
        "    m = int(i[1])-1\n",
        "    order_count+=1\n",
        "    prev = int(i[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-437559bedc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0morder_binary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m135\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0morders_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_orders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbaskets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_orders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-vXoLWTFS-D"
      },
      "source": [
        "#data processing evalusation set\n",
        "eval_fullorders=[]\n",
        "order_binary=[[0 for x in range(135)] for y in range(1)]\n",
        "orders_binary = []\n",
        "for i in eval_orders: \n",
        "    if(int(i[0])!=prev):\n",
        "        baskets=[]\n",
        "        eval_fullorders.append(baskets)\n",
        "    baskets.append(i[1])\n",
        "    m = int(i[1])-1\n",
        "    order_count+=1\n",
        "    prev = int(i[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF1hMjspt0Su",
        "outputId": "10f707e1-e0b8-4ea0-d70f-9d6526c64fe0"
      },
      "source": [
        "#create orders of only 60 categories with the new number for categorie equal to the i-th accepted categorie in order of its' original number\n",
        "import numpy as np\n",
        "orders_bin = np.array(orders_binary)\n",
        "remove_cat = orders_bin.T\n",
        "acceptedCategories = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "m=0\n",
        "count=0\n",
        "orders_binary_T=remove_cat.tolist()\n",
        "orders2=[]\n",
        "for i in orders:\n",
        "  accorders_T=[]\n",
        "  for j in i:\n",
        "    if (int(j) in acceptedCategories):\n",
        "        m+=1\n",
        "        accorders_T.append(j)\n",
        "    count+=1\n",
        "  orders2.append(accorders_T)\n",
        "print(\"orders:\",len(orders2))\n",
        "orders_60_T = np.array(accorders_T)\n",
        "orders_60 = orders_60_T.T\n",
        "count=0\n",
        "print(orders2[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "orders: 30001\n",
            "[120, 91, 123, 123, 91, 83, 35, 112]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWzeSej7AtKW",
        "outputId": "b14771b2-d718-4994-9347-f2b7c32f3607"
      },
      "source": [
        "#create orders of only 60 categories with the new number for categorie equal to the i-th accepted categorie in order of its' original number for evaluation set\n",
        "import numpy as np\n",
        "orders_bin = np.array(orders_binary)\n",
        "remove_cat = orders_bin.T\n",
        "acceptedCategories = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "m=0\n",
        "count=0\n",
        "orders_binary_T=remove_cat.tolist()\n",
        "orders2_eval=[]\n",
        "for i in eval_fullorders:\n",
        "  accorders_T=[]\n",
        "  for j in i:\n",
        "    if (int(j) in acceptedCategories):\n",
        "        m+=1\n",
        "        accorders_T.append(j)\n",
        "    count+=1\n",
        "  orders2_eval.append(accorders_T)\n",
        "print(\"orders:\",len(orders2_eval))\n",
        "orders_60_T = np.array(accorders_T)\n",
        "orders_60_eval = orders_60_T.T\n",
        "count=0\n",
        "print(orders2_eval[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "orders: 10001\n",
            "[120, 108, 83, 83, 24, 24, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "uQKuI1OxxZm4",
        "outputId": "1710cd0b-d325-4abb-c352-6914f1677696"
      },
      "source": [
        "#create dataset file for training\n",
        "import random\n",
        "file1 = open(\"ArtData.txt\",\"w\")\n",
        "for i in orders2:\n",
        "  #for l in range(6):\n",
        "    str1 =\"\"\n",
        "    for j in i:\n",
        "      if(str(j) not in str1):\n",
        "        str1 = str1 + \" \"+ str(j) \n",
        "    str1 += \" end .\"\n",
        "    file1.write(str1)\n",
        "    #random.shuffle(i)\n",
        "file1.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-e4ffaa392250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ArtData.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morders2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m#for l in range(6):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstr1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'orders2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmYjj7chxEUF"
      },
      "source": [
        "#create dataset file for evaluation\n",
        "import random\n",
        "file2 = open(\"artData.txt\",\"w\")\n",
        "for i in orders2_eval:\n",
        "    str2 =\"\"\n",
        "    for j in i:\n",
        "      if(str(j) not in str2):\n",
        "        str2 = str2 + \" \"+ str(j)\n",
        "    str2 += \".\"\n",
        "    file2.write(str2)\n",
        "    #random.shuffle(i)\n",
        "file2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VH47e60pwas",
        "outputId": "eaddbcea-521e-4048-9436-bf0a8fee0051"
      },
      "source": [
        "#Data is created and should be loaded, create tokenizer\n",
        "!pip install tokenizers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "tokenizer = BertWordPieceTokenizer(\n",
        "  clean_text=False,\n",
        "  handle_chinese_chars=False,\n",
        "  strip_accents=False,\n",
        "  lowercase=True,\n",
        ")\n",
        "files = ['myfileNoRepl6.txt']\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(\n",
        "  files,\n",
        "  vocab_size=100,\n",
        "  min_frequency=3,\n",
        "  show_progress=True,\n",
        "  special_tokens=['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'],\n",
        "  limit_alphabet=1000,\n",
        "  wordpieces_prefix=\"##\"\n",
        ")\n",
        "# Save files to disk\n",
        "tokenizer.save_model(\".\", \"Cross2Bert\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 8.4MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./Cross2Bert-vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbxX3O_mI7v4",
        "outputId": "d9262e8d-2ca6-40fc-f963-2e7a74a61d2d"
      },
      "source": [
        "#Tokenizer add special tokens\n",
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = BertWordPieceTokenizer(\n",
        "        \"/content/Cross2Bert-vocab.txt\"\n",
        "        )\n",
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
        "    (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=60)\n",
        "hello = tokenizer.encode(\"83 17 35\")\n",
        "print(\n",
        "    hello\n",
        ")\n",
        "print(hello.tokens)\n",
        "# Encoding(num_tokens=7, ...)\n",
        "# tokens: ['<s>', 'Mi', 'Ġestas', 'ĠJuli', 'en', '.', '</s>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "['[CLS]', '83', '17', '35', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4H4TKzRGJIA"
      },
      "source": [
        "#Tokenize training set\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CrossBertDataset(Dataset):\n",
        "    def __init__(self, evaluate: bool = True):\n",
        "        tokenizer = BertWordPieceTokenizer(\n",
        "        \"/content/Cross2Bert-vocab.txt\"\n",
        "        )\n",
        "        tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "            (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
        "            (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
        "        )\n",
        "        tokenizer.enable_truncation(max_length=100)\n",
        "        # or use the RobertaTokenizer from `transformers` directly.\n",
        "\n",
        "        self.examples = []\n",
        "\n",
        "        src_files = Path(\"/content/\").glob(\"myfileNoRepl6.txt\") if evaluate else Path(\"/content/\").glob(\"myfile_eval.txt\")\n",
        "        for src_file in src_files:\n",
        "            print(\"hello\", src_file)\n",
        "            lines = src_file.read_text(encoding=\"utf-8\").split(\".\")\n",
        "            \n",
        "            self.examples += [x.ids for x in tokenizer.encode_batch(lines)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # We’ll pad at the batch level.\n",
        "        return torch.tensor(self.examples[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Naqu6_yZWxMN"
      },
      "source": [
        "#Tokenize evaluation set\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CrossBertDataset_eval(Dataset):\n",
        "    def __init__(self, evaluate: bool = False):\n",
        "        tokenizer = BertWordPieceTokenizer(\n",
        "        \"/content/Cross2Bert-vocab.txt\"\n",
        "        )\n",
        "        tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "            (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
        "            (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
        "        )\n",
        "        tokenizer.enable_truncation(max_length=100)\n",
        "        # or use the RobertaTokenizer from `transformers` directly.\n",
        "\n",
        "        self.examples = []\n",
        "\n",
        "        src_files = Path(\"/content/\").glob(\"myfile.txt\") if evaluate else Path(\"/content/\").glob(\"myfile_evalNoRepl6.txt\")\n",
        "        for src_file in src_files:\n",
        "            print(\"hello\", src_file)\n",
        "            lines = src_file.read_text(encoding=\"utf-8\").split(\".\")\n",
        "            \n",
        "            self.examples += [x.ids for x in tokenizer.encode_batch(lines)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # We’ll pad at the batch level.\n",
        "        return torch.tensor(self.examples[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRcC6VOiPY1v",
        "outputId": "fabf744c-93dc-4383-bb39-0a5c07ff69be"
      },
      "source": [
        "#Give parameters for funtction\n",
        "!pip install transformers\n",
        "from transformers import BertModel, BertConfig, BertForMaskedLM\n",
        "\n",
        "config = BertConfig(\n",
        "    vocab_size=100,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=12,\n",
        "    type_vocab_size=1,\n",
        ")\n",
        "\n",
        "model = BertForMaskedLM(config)\n",
        "model.num_parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/d5/c6c23ad75491467a9a84e526ef2364e523d45e2b0fae28a7cbe8689e7e84/transformers-4.8.1-py3-none-any.whl (2.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 25.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 17.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 40kB 14.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 51kB 8.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |█                               | 81kB 10.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 92kB 10.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 112kB 8.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 122kB 8.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 133kB 8.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 143kB 8.5MB/s eta 0:00:01\r\u001b[K     |██                              | 153kB 8.5MB/s eta 0:00:01\r\u001b[K     |██                              | 163kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 174kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 184kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 194kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 204kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 215kB 8.5MB/s eta 0:00:01\r\u001b[K     |███                             | 225kB 8.5MB/s eta 0:00:01\r\u001b[K     |███                             | 235kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 245kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 256kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 266kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 276kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 286kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 296kB 8.5MB/s eta 0:00:01\r\u001b[K     |████                            | 307kB 8.5MB/s eta 0:00:01\r\u001b[K     |████                            | 317kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 327kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 337kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 348kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 358kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 368kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 378kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 389kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 399kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 409kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 419kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 430kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 440kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 450kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 460kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 471kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 481kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 491kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 501kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 512kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 522kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 532kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 542kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 552kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 563kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 573kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 583kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 593kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 604kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 614kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 624kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 634kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 645kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 655kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 665kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 675kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 686kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 696kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 706kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 716kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 727kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 737kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 747kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 757kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 768kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 778kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 788kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 798kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 808kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 819kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 829kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 839kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 849kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 860kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 870kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 880kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 890kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 901kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 911kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 921kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 931kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 942kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 952kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 962kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 972kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 983kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 993kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.6MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.7MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.8MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.9MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.4MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 transformers-4.8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86120548"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI7JEvKEPu3i"
      },
      "source": [
        "#Load tokenizer for model\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer(\"/content/Cross2Bert-vocab.txt\", max_len=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eTzCKhNR0R7"
      },
      "source": [
        "#Mask the data\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNpkdDjTMC50",
        "outputId": "36af8d18-4abb-4843-ca37-02a2dcef9d27"
      },
      "source": [
        "#Create training object\n",
        "from transformers import Trainer, TrainingArguments\n",
        "!pip install torch\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/CrossBert_10epoch_0.15_6shuffle\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=CrossBertDataset(),\n",
        "    #eval_dataset=CrossBertDataset_eval(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "hello /content/myfileNoRepl6.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "o3lWGNcpEhK5",
        "outputId": "81e35f6f-5c41-47ea-c396-9d3a92aaa452"
      },
      "source": [
        "#Start training\n",
        "%%time\n",
        "import torch\n",
        "#trainer.num_examples()\n",
        "trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "***** Running training *****\n",
            "  Num examples = 180007\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 28130\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='958' max='28130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  958/28130 02:22 < 1:07:27, 6.71 it/s, Epoch 0.34/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.752000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1160' max='28130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1160/28130 02:52 < 1:06:52, 6.72 it/s, Epoch 0.41/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.752000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.436500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "DAqzN2DEIjch",
        "outputId": "2765c947-8cd5-435c-bf4e-c806daedd1ee"
      },
      "source": [
        "#Evaluate model\n",
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7501' max='7501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7501/7501 01:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 1.0,\n",
              " 'eval_loss': 3.2109930515289307,\n",
              " 'eval_runtime': 63.2628,\n",
              " 'eval_samples_per_second': 948.536,\n",
              " 'eval_steps_per_second': 118.569}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC3KMOgb9LT-"
      },
      "source": [
        "#Save model\n",
        "trainer.save_model(\"/content/Model_10Epoch_0.15_6shuffle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgWA9LRYmJyE",
        "outputId": "73c9a7ba-e50a-419f-ec90-65aff34cae54"
      },
      "source": [
        "#Create object that calculated probability of masked object\n",
        "!pip install transformers\n",
        "from transformers import pipeline\n",
        "from transformers import BertTokenizer,BertConfig,BertForMaskedLM,BertModel\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model =\"/content/Model_10Epoch_0.15_6shuffle\" ,\n",
        "    tokenizer= BertTokenizer(\"/content/Cross2Bert-vocab.txt\", max_len=60),\n",
        "    top_k=2                 \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loading configuration file /content/Model_10Epoch_0.15_6shuffle/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.8.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100\n",
            "}\n",
            "\n",
            "loading configuration file /content/Model_10Epoch_0.15_6shuffle/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.8.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100\n",
            "}\n",
            "\n",
            "loading weights file /content/Model_10Epoch_0.15_6shuffle/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
            "\n",
            "All the weights of BertForMaskedLM were initialized from the model checkpoint at /content/Model_10Epoch_0.15_6shuffle.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47R7ub42WV16",
        "outputId": "688f3c76-5d5c-48e9-dcf8-d6af037e0eea"
      },
      "source": [
        "fullTokens = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "fullTokens.sort()\n",
        "print(fullTokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 4, 9, 16, 17, 19, 21, 23, 24, 26, 31, 32, 35, 36, 37, 38, 43, 45, 49, 50, 51, 52, 53, 54, 59, 61, 63, 66, 67, 69, 72, 77, 78, 79, 81, 83, 84, 86, 88, 91, 92, 93, 94, 96, 98, 104, 106, 107, 108, 112, 115, 116, 117, 120, 121, 123, 128, 129, 130, 131]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtZrvgZymYjg"
      },
      "source": [
        "with open('artData.txt') as f:\n",
        "    lines = f.read()\n",
        "    currentline = lines.split(\".\")\n",
        "counts = []\n",
        "for i in currentline:\n",
        "  counts.append(i.count(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "AdE_GK3qpFAv",
        "outputId": "cfac3dce-d9e6-49f5-cf0d-9d92f5e6d1aa"
      },
      "source": [
        "#distribution of the data length\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# fixed bin size\n",
        "bins = np.arange(-100, 100, 1) # fixed bin size\n",
        "\n",
        "plt.xlim([0, 25])\n",
        "\n",
        "plt.hist(counts, bins=bins, alpha=0.5)\n",
        "plt.title('Distribution Lengths Orders')\n",
        "plt.xlabel('Order Size')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kRYAx7OXsRF"
      },
      "source": [
        "#Create artificial orders using bert\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "class artOrders():\n",
        "  def __init__(self):\n",
        "    self.artOrder= \"\"\n",
        "\n",
        "  def maskWord(self,orderList, fullTokens, length):\n",
        "      if(length>5):\n",
        "        length = length-2\n",
        "      order = \" \".join(orderList)\n",
        "      prev  = 0\n",
        "      artOrder =  \"\"\n",
        "      for j in fullTokens:\n",
        "        n = random.random()\n",
        "        strJ = str(j)\n",
        "        copyOrder = order.replace(strJ, '')\n",
        "        y = fill_mask.__call__(str(copyOrder), targets=strJ)\n",
        "        df = pd.DataFrame(y)\n",
        "        score =(df.loc[0]['score'])\n",
        "        probNot =(1-(1-score)**length)\n",
        "        if(n<probNot):\n",
        "          self.artOrder += strJ + \" \"\n",
        "      return\n",
        "\n",
        "  def main(self,order, fullTokens, length):\n",
        "      self.artOrder = \"\"\n",
        "      orderList = order.split(\" \")\n",
        "      orderList.remove(\"\")\n",
        "      if (length%2==0):\n",
        "          midpoint = length/2\n",
        "      else:\n",
        "          midpoint = (length+1)/2\n",
        "      orderList2 = orderList[0:int(midpoint)] + [\"[MASK]\"] + orderList[int(midpoint):]\n",
        "      self.maskWord(orderList2,fullTokens, length)\n",
        "      return self.artOrder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAfw97H5e53F",
        "outputId": "d314d613-bb74-4380-e442-b5547f9efc53"
      },
      "source": [
        "#Restructure artificial orders in binary data\n",
        "artDataset=[]\n",
        "with open('artData.txt') as f:\n",
        "    lines = f.read()\n",
        "    currentline = lines.split(\".\")\n",
        "dataset1 = artOrders()\n",
        "count = 0\n",
        "for i in currentline:\n",
        "  if(count%100==0):\n",
        "    print(count, \" of 10000\")\n",
        "  if(count == 10000):\n",
        "    break\n",
        "  fullTokens = [3, 4, 9, 16, 17, 19, 21, 23, 24, 26, 31, 32, 35, 36, 37, 38, 43, 45, 49, 50,\n",
        "                         51, 52, 53, 54, 59, 61, 63, 66, 67, 69, 72, 77, 78, 79, 81, 83, 84, 86, 88, \n",
        "                         91, 92, 93, 94, 96, 98, 104, 106, 107, 108, 112, 115, 116, 117, 120, 121, 123,\n",
        "                         128, 129, 130, 131]\n",
        "  artDataset.append(dataset1.main(i,fullTokens,random.choice(counts)))\n",
        "  count+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  of 10000\n",
            "100  of 10000\n",
            "200  of 10000\n",
            "300  of 10000\n",
            "400  of 10000\n",
            "500  of 10000\n",
            "600  of 10000\n",
            "700  of 10000\n",
            "800  of 10000\n",
            "900  of 10000\n",
            "1000  of 10000\n",
            "1100  of 10000\n",
            "1200  of 10000\n",
            "1300  of 10000\n",
            "1400  of 10000\n",
            "1500  of 10000\n",
            "1600  of 10000\n",
            "1700  of 10000\n",
            "1800  of 10000\n",
            "1900  of 10000\n",
            "2000  of 10000\n",
            "2100  of 10000\n",
            "2200  of 10000\n",
            "2300  of 10000\n",
            "2400  of 10000\n",
            "2500  of 10000\n",
            "2600  of 10000\n",
            "2700  of 10000\n",
            "2800  of 10000\n",
            "2900  of 10000\n",
            "3000  of 10000\n",
            "3100  of 10000\n",
            "3200  of 10000\n",
            "3300  of 10000\n",
            "3400  of 10000\n",
            "3500  of 10000\n",
            "3600  of 10000\n",
            "3700  of 10000\n",
            "3800  of 10000\n",
            "3900  of 10000\n",
            "4000  of 10000\n",
            "4100  of 10000\n",
            "4200  of 10000\n",
            "4300  of 10000\n",
            "4400  of 10000\n",
            "4500  of 10000\n",
            "4600  of 10000\n",
            "4700  of 10000\n",
            "4800  of 10000\n",
            "4900  of 10000\n",
            "5000  of 10000\n",
            "5100  of 10000\n",
            "5200  of 10000\n",
            "5300  of 10000\n",
            "5400  of 10000\n",
            "5500  of 10000\n",
            "5600  of 10000\n",
            "5700  of 10000\n",
            "5800  of 10000\n",
            "5900  of 10000\n",
            "6000  of 10000\n",
            "6100  of 10000\n",
            "6200  of 10000\n",
            "6300  of 10000\n",
            "6400  of 10000\n",
            "6500  of 10000\n",
            "6600  of 10000\n",
            "6700  of 10000\n",
            "6800  of 10000\n",
            "6900  of 10000\n",
            "7000  of 10000\n",
            "7100  of 10000\n",
            "7200  of 10000\n",
            "7300  of 10000\n",
            "7400  of 10000\n",
            "7500  of 10000\n",
            "7600  of 10000\n",
            "7700  of 10000\n",
            "7800  of 10000\n",
            "7900  of 10000\n",
            "8000  of 10000\n",
            "8100  of 10000\n",
            "8200  of 10000\n",
            "8300  of 10000\n",
            "8400  of 10000\n",
            "8500  of 10000\n",
            "8600  of 10000\n",
            "8700  of 10000\n",
            "8800  of 10000\n",
            "8900  of 10000\n",
            "9000  of 10000\n",
            "9100  of 10000\n",
            "9200  of 10000\n",
            "9300  of 10000\n",
            "9400  of 10000\n",
            "9500  of 10000\n",
            "9600  of 10000\n",
            "9700  of 10000\n",
            "9800  of 10000\n",
            "9900  of 10000\n",
            "10000  of 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jGgBYgbI_XFM",
        "outputId": "3a736cd3-2082-46a8-fdd5-66635b997248"
      },
      "source": [
        "#Create data to get the orders in binary numbers\n",
        "orders_binary= []\n",
        "fullTokens = [3, 4, 9, 16, 17, 19, 21, 23, 24, 26, 31, 32, 35, 36, 37, 38, 43, 45, 49, 50,\n",
        "                         51, 52, 53, 54, 59, 61, 63, 66, 67, 69, 72, 77, 78, 79, 81, 83, 84, 86, 88, \n",
        "                         91, 92, 93, 94, 96, 98, 104, 106, 107, 108, 112, 115, 116, 117, 120, 121, 123,\n",
        "                         128, 129, 130, 131]\n",
        "for i in artDataset:\n",
        "  order_binary = [[0 for x in range(135)] for y in range(1)]\n",
        "  data = i.split(\" \")\n",
        "  data.remove('')\n",
        "  for j in data:\n",
        "    m = int(j)-1\n",
        "    if (order_binary[0][m]==0):\n",
        "      order_binary[0][m]+=1\n",
        "    order_count+=1\n",
        "  orders_binary.append(order_binary)\n",
        "count = 0\n",
        "print(orders_binary[0])\n",
        "import numpy as np\n",
        "\n",
        "orders_bin = np.array(orders_binary)\n",
        "remove_cat = orders_bin.T\n",
        "acceptedCategories = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "m=0\n",
        "count=0\n",
        "orders_binary_T=remove_cat.tolist()\n",
        "accorders_T=[]\n",
        "for i in orders_binary_T:\n",
        "    if (count+1 in acceptedCategories):\n",
        "        m+=1\n",
        "        accorders_T.append(i)\n",
        "    count+=1\n",
        "print(\"orders:\",len(accorders_T))\n",
        "orders_60_T = np.array(accorders_T)\n",
        "orders_60 = orders_60_T.T\n",
        "count=0\n",
        "orders_60Art = orders_60"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "orders: 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N3d_JFG7aCB7",
        "outputId": "20f29363-5372-4f3c-8335-d1cd289d3e68"
      },
      "source": [
        "#Create list of art order sizes\n",
        "lengths=[]\n",
        "for i in artDataset:\n",
        "  lengths.append(i.count(\" \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21 24 32 49 92 96 123 \n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-TtCn8RCZ4DF",
        "outputId": "73b37d35-6601-42f9-e01e-8c3b26b15384"
      },
      "source": [
        "#distribution of the data length\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# fixed bin size\n",
        "bins = np.arange(-100, 100, 1) # fixed bin size\n",
        "\n",
        "plt.xlim([0, 25])\n",
        "\n",
        "plt.hist(lengths, bins=bins, alpha=0.5)\n",
        "plt.title('Distribution Lengths Orders')\n",
        "plt.xlabel('Order Size')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6_KsLSCCnqh"
      },
      "source": [
        "#Creates arra\n",
        "import csv\n",
        "train_orders=[]\n",
        "with open('/content/order_products__train.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    order_count=0\n",
        "    prev=-1\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            #print(f'\\t product_id :{row[0]}| product_name: {row[1]} | aisle_id: {row[2]} | department_id : {row[3]}')\n",
        "                if (int(row[0])!=prev):\n",
        "                    order_count+=1\n",
        "                order_basket = [int(row[0]),getAisleID(int(row[1]))]\n",
        "                train_orders.append(order_basket)\n",
        "                prev = int(row[0])\n",
        "                line_count += 1\n",
        "                if(order_count==10000):\n",
        "                    break\n",
        "    print(f'Processed {line_count} lines.')\n",
        "\n",
        "orders=[]\n",
        "order_binary=[[0 for x in range(135)] for y in range(1)]\n",
        "orders_binary = []\n",
        "for i in train_orders: \n",
        "    if(int(i[0])!=prev):\n",
        "        baskets=[]\n",
        "        orders.append(baskets)\n",
        "        order_binary = [[0 for x in range(135)] for y in range(1)]\n",
        "        orders_binary.append(order_binary)\n",
        "    baskets.append(i[1])\n",
        "    m = int(i[1])-1\n",
        "    if (order_binary[0][m]==0):\n",
        "        order_binary[0][m]+=1\n",
        "    order_count+=1\n",
        "    prev = int(i[0])\n",
        "print(orders_binary[0])\n",
        "#create orders of only 60 categories with the new number for categorie equal to the i-th accepted categorie in order of its' original number\n",
        "import numpy as np\n",
        "orders_bin = np.array(orders_binary)\n",
        "remove_cat = orders_bin.T\n",
        "acceptedCategories = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "m=0\n",
        "count=0\n",
        "orders_binary_T=remove_cat.tolist()\n",
        "accorders_T=[]\n",
        "for i in orders_binary_T:\n",
        "    if (count+1 in acceptedCategories):\n",
        "        m+=1\n",
        "        accorders_T.append(i)\n",
        "    count+=1\n",
        "print(\"orders:\",len(accorders_T))\n",
        "orders_60_T = np.array(accorders_T)\n",
        "orders_60 = orders_60_T.T\n",
        "count=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Nk7XmSLi-E"
      },
      "source": [
        "#Calculate AD for artificial orders\n",
        "import numpy as np\n",
        "AD=np.zeros((500,10000,1,60))\n",
        "for i in range(len(orders_60Art)):\n",
        "    AD += abs(orders_60[i][0]-orders_60Art[i][0])\n",
        "AD=AD/len(orders_60Art)\n",
        "sumAdRbm = AD.sum(axis=0)\n",
        "sumAdRbm = sumAdRbm.sum(axis=0)\n",
        "adRbm = sum(sumAdRbm)\n",
        "print(adRbm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vaFZ8FQMukW"
      },
      "source": [
        "#Cross-effects calculations function\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "\n",
        "class getCrossEffects():\n",
        "  def __init__(self, target, k, n):\n",
        "    self.n = n\n",
        "    self.target = target\n",
        "    self.k = k\n",
        "    self.fullTokens = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "    self.tokensRest = [e for e in self.fullTokens if e not in (target, k)]\n",
        "\n",
        "    #self.tokens = self.fullTokens.remove(self.target)\n",
        "    #self.tokensRest = self.tokens.remove(self.k)\n",
        "\n",
        "  def getRandomOrders(self):\n",
        "    random_ordersNoK = []\n",
        "    random_ordersWithK = []\n",
        "    for i in range(self.n):\n",
        "      orderNoK = \"\"\n",
        "      orderWithK = \"\"\n",
        "      order_size = random.randint(2,20)\n",
        "      if(order_size<0):\n",
        "        order_size=2\n",
        "      target_element = random.randint(0, order_size)\n",
        "      k_element = random.randint(0, order_size)\n",
        "      while(k_element == target_element):\n",
        "        k_element = random.randint(0, order_size)\n",
        "      for j in range(int(order_size)):\n",
        "        random_element = random.choice(self.tokensRest)\n",
        "        if(j == k_element):\n",
        "          orderWithK+= str(self.k) + \" \"\n",
        "          orderNoK += str(random_element)+ \" \"\n",
        "          continue\n",
        "        if(j == target_element):\n",
        "          orderNoK+=\"[MASK]\" + \" \"\n",
        "          orderWithK += \"[MASK]\"+\" \"\n",
        "        orderNoK += str(random_element)+ \" \"\n",
        "        orderWithK += str(random_element)+\" \"\n",
        "      random_ordersNoK.append(orderNoK)\n",
        "      random_ordersWithK.append(orderWithK)\n",
        "    return random_ordersNoK, random_ordersWithK\n",
        "\n",
        "  def scoreYesK(self, random_ordersWithK):\n",
        "    sumYesK=0\n",
        "    for order in random_ordersWithK:\n",
        "      y = fill_mask.__call__(order, targets=str(self.target)+ \" \")\n",
        "      df = pd.DataFrame(y)\n",
        "      sumYesK +=df.loc[0]['score']\n",
        "    return sumYesK\n",
        "\n",
        "  def scoreNoK(self, random_ordersNoK):\n",
        "    sumNoK=0\n",
        "    for order in random_ordersNoK:\n",
        "      y = fill_mask.__call__(order, targets=str(self.target))\n",
        "      df = pd.DataFrame(y)\n",
        "      sumNoK +=df.loc[0]['score']\n",
        "    return sumNoK\n",
        "  def getPercentage(self):\n",
        "    random_ordersNoK, random_ordersWithK = self.getRandomOrders()\n",
        "    change = self.main()\n",
        "    \n",
        "    return perc\n",
        "\n",
        "  def main(self):\n",
        "    random_ordersNoK, random_ordersWithK = self.getRandomOrders()\n",
        "    scoreYesK = self.scoreYesK(random_ordersWithK)\n",
        "    scoreNoK = self.scoreNoK(random_ordersNoK)\n",
        "    crossProb = (scoreYesK - scoreNoK)/len(random_ordersWithK)\n",
        "    perc = crossProb / (self.scoreNoK(random_ordersNoK)/len(random_ordersNoK))\n",
        "    return crossProb, perc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msckbSfMiqN-"
      },
      "source": [
        "#Write the cross-effects\n",
        "import math\n",
        "import time\n",
        "import math\n",
        "Tokens = [24,83,123,120,21,84,115,107,91,112,86,31,116,37,78,96,\n",
        "                         67,16,121,77,98,54,72,50,108,36,52,63,69,17,61,66,4,\n",
        "                         32,130,53,106,3,38,81,88,117,131,128,92,19,104,49,59,\n",
        "                         26,43,9,129,35,93,79,51,45,94,23]\n",
        "Tokens.sort()\n",
        "tStats = np.zeros((60,60))\n",
        "StDevs = np.zeros((60,60))\n",
        "averages = np.zeros((60,60))\n",
        "t0 = time.time()\n",
        "count = 30\n",
        "for i in range(6,12):\n",
        "  nameCrossEffects = \"tstatsBert\" + str(i) + \".txt\"\n",
        "  nameAverage = \"averagesBert\"+ str(i) + \".txt\"\n",
        "  namePercIncr = \"percentageBert\"+ str(i) + \".txt\"\n",
        "  #tStatsBERT = open(nameCrossEffects,\"w\")\n",
        "  averagesBERT = open(nameAverage,\"w\")\n",
        "  percentageIncreasingBERT = open(namePercIncr,\"w\")\n",
        "  for z in range(5):\n",
        "    for j in range(60):\n",
        "      average=[]\n",
        "      totalP = 0\n",
        "      average = 0\n",
        "      tStat = 0\n",
        "      totalperc=0\n",
        "      x = []\n",
        "      cross = getCrossEffects(Tokens[count],Tokens[j],25)\n",
        "      datasets = 1\n",
        "      print(j)\n",
        "      for k in range(datasets):\n",
        "        x_i,perc = cross.main()\n",
        "        x.append(x_i)\n",
        "        totalP +=x_i\n",
        "        totalperc+=perc\n",
        "      average = totalP/ datasets\n",
        "      averagePerc = totalperc/datasets\n",
        "      #std = np.sqrt(np.sum(np.power(np.array(x) - average,2))/datasets)\n",
        "      #tStat = average / (std/math.sqrt(datasets))\n",
        "      #tStatsBERT.write(str(tStat)+\", \")\n",
        "      averagesBERT.write(str(average)+\", \")\n",
        "      percentageIncreasingBERT.write(str(averagePerc)+\", \")\n",
        "    print(count,j)\n",
        "    count +=1\n",
        "  averagesBERT.close()\n",
        "  #tStatsBERT.close()\n",
        "  percentageIncreasingBERT.close()\n",
        "print(\"cat :\", i , \" calculated\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}